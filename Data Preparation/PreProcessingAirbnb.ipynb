{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Afif Shomali\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing Airbnb Data\n",
    "Source: Inside Airbnb accessed at https://insideairbnb.com/get-the-data/ (Used New York City Datasets, used listings & reviews data)  \n",
    "License : [Creative Commons Attribution 4.0 International License](#https://creativecommons.org/licenses/by/4.0/)\n",
    "\n",
    "## Overview of Steps:\n",
    "- [Merge all data into dataset, removing duplicates by keeping most recent version of a listing](#merging-datasets)\n",
    "- [Go through and remove uneeded columns](#unecessary-column-removalpruning)\n",
    "- [Clean up Missing Values in dataset, impute using zero, median or average, remove row completely if needed](#handling-missing-values)\n",
    "- [Converting datatypes of certain columns, like price & True/False cols, string list to list columns, datetime](#converting-datatypes-of-columns)\n",
    "\n",
    "After these steps we can move to feature engineering, this work is done in the `FeatureEngineering.ipynb` Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42432"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Commented out in order to keep dataset size reasonable\n",
    "# # Merging Step, don't run this part if only using subset\n",
    "# df = pd.read_csv(\"Datasets/AirbnbData/Sep.csv\")\n",
    "\n",
    "# print(df.shape)\n",
    "# months = [\"Aug\", \"July\", \"June\", \"May\"]\n",
    "\n",
    "# for month in months:\n",
    "#     df_2 = pd.read_csv(f\"Datasets/AirbnbData/{month}.csv\")\n",
    "    \n",
    "#     df = pd.concat([\n",
    "#         df, \n",
    "#         df_2[df_2[\"id\"].isin(df[\"id\"]) == False]\n",
    "#     ]\n",
    "#     ).reset_index(drop=True)\n",
    "\n",
    "# print(df.shape)\n",
    "\n",
    "# # Checking that we do not have duplicate listings\n",
    "# len(df[\"id\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unecessary Column Removal/Pruning \n",
    "\n",
    "Columns to Remove:\n",
    "- listing_url\n",
    "- scrape_id\n",
    "- source\n",
    "- host_url\n",
    "- host_thumbnail_url\n",
    "- host_picture_url\n",
    "- calendar_updated\n",
    "- calendar_last_scraped\n",
    "- first_review\n",
    "- last_review\n",
    "\n",
    "These don't provide us with any useful information for the goal of creating a predictive model, these columns were selecting after looking over the [data descritpion](https://docs.google.com/spreadsheets/d/1iWCNJcSutYqpULSQHlNyGInUvHg2BoUGoNRIGa6Szc4/edit?gid=1322284596#gid=1322284596), we will likely drop more columns later on after conducting EDA which might uncover more columns as being not impactful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'listing_url', 'scrape_id', 'last_scraped', 'source', 'name',\n",
       "       'description', 'neighborhood_overview', 'picture_url', 'host_id',\n",
       "       'host_url', 'host_name', 'host_since', 'host_location', 'host_about',\n",
       "       'host_response_time', 'host_response_rate', 'host_acceptance_rate',\n",
       "       'host_is_superhost', 'host_thumbnail_url', 'host_picture_url',\n",
       "       'host_neighbourhood', 'host_listings_count',\n",
       "       'host_total_listings_count', 'host_verifications',\n",
       "       'host_has_profile_pic', 'host_identity_verified', 'neighbourhood',\n",
       "       'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'latitude',\n",
       "       'longitude', 'property_type', 'room_type', 'accommodates', 'bathrooms',\n",
       "       'bathrooms_text', 'bedrooms', 'beds', 'amenities', 'price',\n",
       "       'minimum_nights', 'maximum_nights', 'minimum_minimum_nights',\n",
       "       'maximum_minimum_nights', 'minimum_maximum_nights',\n",
       "       'maximum_maximum_nights', 'minimum_nights_avg_ntm',\n",
       "       'maximum_nights_avg_ntm', 'calendar_updated', 'has_availability',\n",
       "       'availability_30', 'availability_60', 'availability_90',\n",
       "       'availability_365', 'calendar_last_scraped', 'number_of_reviews',\n",
       "       'number_of_reviews_ltm', 'number_of_reviews_l30d', 'first_review',\n",
       "       'last_review', 'review_scores_rating', 'review_scores_accuracy',\n",
       "       'review_scores_cleanliness', 'review_scores_checkin',\n",
       "       'review_scores_communication', 'review_scores_location',\n",
       "       'review_scores_value', 'license', 'instant_bookable',\n",
       "       'calculated_host_listings_count',\n",
       "       'calculated_host_listings_count_entire_homes',\n",
       "       'calculated_host_listings_count_private_rooms',\n",
       "       'calculated_host_listings_count_shared_rooms', 'reviews_per_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the combined dataset \n",
    "df = pd.read_csv(\"Datasets/AirbnbData/Full_listings.csv\")\n",
    "\n",
    "# Get an idea of what all the columns are\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\n",
    "    \"listing_url\",\n",
    "    \"scrape_id\",\n",
    "    \"source\",\n",
    "    \"host_url\",\n",
    "    \"host_thumbnail_url\",\n",
    "    \"host_picture_url\",\n",
    "    \"calendar_updated\",\n",
    "    \"calendar_last_scraped\",\n",
    "    \"first_review\",\n",
    "    \"last_review\",\n",
    "    \"neighbourhood\"\n",
    "]\n",
    "df.drop(drop_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'last_scraped', 'name', 'description', 'neighborhood_overview',\n",
       "       'picture_url', 'host_id', 'host_name', 'host_since', 'host_location',\n",
       "       'host_about', 'host_response_time', 'host_response_rate',\n",
       "       'host_acceptance_rate', 'host_is_superhost', 'host_neighbourhood',\n",
       "       'host_listings_count', 'host_total_listings_count',\n",
       "       'host_verifications', 'host_has_profile_pic', 'host_identity_verified',\n",
       "       'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'latitude',\n",
       "       'longitude', 'property_type', 'room_type', 'accommodates', 'bathrooms',\n",
       "       'bathrooms_text', 'bedrooms', 'beds', 'amenities', 'price',\n",
       "       'minimum_nights', 'maximum_nights', 'minimum_minimum_nights',\n",
       "       'maximum_minimum_nights', 'minimum_maximum_nights',\n",
       "       'maximum_maximum_nights', 'minimum_nights_avg_ntm',\n",
       "       'maximum_nights_avg_ntm', 'has_availability', 'availability_30',\n",
       "       'availability_60', 'availability_90', 'availability_365',\n",
       "       'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d',\n",
       "       'review_scores_rating', 'review_scores_accuracy',\n",
       "       'review_scores_cleanliness', 'review_scores_checkin',\n",
       "       'review_scores_communication', 'review_scores_location',\n",
       "       'review_scores_value', 'license', 'instant_bookable',\n",
       "       'calculated_host_listings_count',\n",
       "       'calculated_host_listings_count_entire_homes',\n",
       "       'calculated_host_listings_count_private_rooms',\n",
       "       'calculated_host_listings_count_shared_rooms', 'reviews_per_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values\n",
    "\n",
    "We will handle missing values using a variety of techniques, imputing values based on median or mean, filling values with zero or estimating a column based on the values of another column.  \n",
    "Additionally, If a column has large proportion of N/A values, we may decide drop the column entirely.\n",
    "The technique use will depend on the column, comments will provide a breif overview as to which technique was used and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: 2\n",
      "description: 1396\n",
      "neighborhood_overview: 19228\n",
      "picture_url: 1\n",
      "host_name: 5\n",
      "host_since: 5\n",
      "host_location: 9503\n",
      "host_about: 18465\n",
      "host_response_time: 15771\n",
      "host_response_rate: 15771\n",
      "host_acceptance_rate: 14948\n",
      "host_is_superhost: 480\n",
      "host_neighbourhood: 8924\n",
      "host_listings_count: 5\n",
      "host_total_listings_count: 5\n",
      "host_verifications: 5\n",
      "host_has_profile_pic: 5\n",
      "host_identity_verified: 5\n",
      "bathrooms: 15539\n",
      "bathrooms_text: 36\n",
      "bedrooms: 6130\n",
      "beds: 15703\n",
      "price: 15544\n",
      "minimum_minimum_nights: 1\n",
      "maximum_minimum_nights: 1\n",
      "minimum_maximum_nights: 1\n",
      "maximum_maximum_nights: 1\n",
      "minimum_nights_avg_ntm: 1\n",
      "maximum_nights_avg_ntm: 1\n",
      "has_availability: 5487\n",
      "review_scores_rating: 13422\n",
      "review_scores_accuracy: 13434\n",
      "review_scores_cleanliness: 13424\n",
      "review_scores_checkin: 13438\n",
      "review_scores_communication: 13429\n",
      "review_scores_location: 13441\n",
      "review_scores_value: 13440\n",
      "license: 36070\n",
      "reviews_per_month: 13422\n"
     ]
    }
   ],
   "source": [
    "# Check which columns have N/A values and how many/what percentage\n",
    "for column in df.columns:\n",
    "    missing_count = df[column].isna().sum()\n",
    "    if missing_count > 0:\n",
    "        print(f'{column}: {missing_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with text columns: name, description, neighborhood_overview, host_name, picture_url, host_about\n",
    "# We will change the missing values to these to just \"Blank\" (Avoids issues when using None since that makes these values NaN when loading),\n",
    "#  when we do a sentiment/text quality analysis, we will automatically give these columns the lowest score/default score\n",
    "df.fillna({\n",
    "    \"name\": \"Blank\",\n",
    "    \"description\": \"Blank\",\n",
    "    \"neighborhood_overview\": \"Blank\",\n",
    "    \"host_name\": \"Blank\",\n",
    "    \"host_about\": \"Blank\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Dropping the row without a picture url since there is only 1 row so it won't reduce our dataset size by any significant amount\n",
    "# This column may or may not be used depending on whether we do feature engineering based on the photo of the airbnb\n",
    "df.dropna(subset=[\"picture_url\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next do Boolean/True False Columns: host_is_superhost, host_has_profile_pic, host_identity_verified, has_availability, license\n",
    "\n",
    "# Columns that will will automatically be false, for these columns, we make the assumption that NaN would be false\n",
    "# since having no value in these columns would correspond to not having superhost status, or not having a profile picture/license \n",
    "df.fillna({\n",
    "    \"host_is_superhost\": \"f\",\n",
    "    \"host_has_profile_pic\": \"f\",\n",
    "    \"license\": \"No License\"\n",
    "}, inplace=True)\n",
    "\n",
    "# To fill host_identity_verified, use the host_verifications which lists what methods of verification the host has, \n",
    "# if this other column is NaN or an empty list then we make the host_identity_verified column false \n",
    "df.loc[df['host_identity_verified'].isna(), 'host_identity_verified'] = df.loc[df['host_identity_verified'].isna(), 'host_verifications'].apply(\n",
    "    lambda x: \"f\" if pd.isna(x) or x == '[]' else \"t\"\n",
    ")\n",
    "\n",
    "# To fill has_availability, use availability_30 to check how many days of availabilty there are in the next 30 days, if this number is > 0 then set the value to true\n",
    "df.loc[df['has_availability'].isna(), 'has_availability'] = df.loc[df['has_availability'].isna(), 'availability_30'].apply(\n",
    "    lambda x: \"t\" if x > 0 else 'f'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then do host related columns that haven't been filled yet: host_since, host_location, host_response_time, host_response_rate, host_acceptance_rate, host_neighbourhood, host_listings_count, host_total_listings_count, host_verifications\n",
    "# host_verifications, fill NaN with '[]' since NaN means the host hasn't been verified\n",
    "df.fillna({\"host_verifications\": '[]'}, inplace=True)\n",
    "\n",
    "# host_since, set value to date of corresponding last_scraped of the column, since that is when that listing was scraped\n",
    "df.loc[df['host_since'].isna(), 'host_since'] = df.loc[df['host_since'].isna(), 'last_scraped']\n",
    "\n",
    "# host_location & host_neighbourhood, if the host neighbourhood is NaN, we fill it with the cleansed listing neighbor hood column\n",
    "# Then we will fill host_location with New York as this should be the default value for listings without a host location \n",
    "# since we are analyzing listings in New York City \n",
    "df.loc[df[\"host_neighbourhood\"].isna(), \"host_neighbourhood\"] = df.loc[df[\"host_neighbourhood\"].isna(), \"neighbourhood_cleansed\"]\n",
    "\n",
    "df.fillna({\"host_location\": \"New York, NY\"}, inplace=True)\n",
    "\n",
    "# host_response_time, host_response_rate, host_acceptance_rate, \n",
    "# want to set NaN response time to the highest possible which is a \"a few days or more\"\n",
    "df.fillna({\"host_response_time\": \"a few days or more\"}, inplace=True)\n",
    "\n",
    "# Want to set  NAN response rate to 0 based on EDA testing this gave us higher correlation between it and predictor variables, \n",
    "# Want to do a similar thing for the host acceptance rate\n",
    "# Make the columns numeric\n",
    "df[\"host_response_rate\"] = df[\"host_response_rate\"].str.rstrip('%').astype(float)\n",
    "df[\"host_acceptance_rate\"] = df[\"host_acceptance_rate\"].str.rstrip(\"%\").astype(float)\n",
    "\n",
    "# Set NaN values to 0 \n",
    "df.fillna({\"host_response_rate\" : 0.0,\n",
    "           \"host_acceptance_rate\": 0.0}, inplace=True)\n",
    "\n",
    "# host_listings_count &  host_total_listings_count, set the values to 1 as we can assume that the host only has 1 version of this listing \n",
    "# Then use the calculated host listing count to fill host_total listing count\n",
    "# Might drop these columns after EDA if we see co-linearity with the calculated host listing column\n",
    "df.fillna({\n",
    "    \"host_listings_count\": 1.0\n",
    "}, inplace=True)\n",
    "\n",
    "df[\"host_total_listings_count\"] = df[\"host_total_listings_count\"].fillna(df[\"calculated_host_listings_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle bed & bathroom columns: bathrooms, bathrooms_text, bedrooms, beds\n",
    "# For bathrooms_text, fill an NaN with \"0 baths\"\n",
    "df.fillna({\n",
    "    \"bathrooms_text\": \"0 baths\"\n",
    "}, inplace=True)\n",
    "\n",
    "# The for the bathrooms column, if the value is NA, use the bathrooms_text column & extract the first number in the string that appears\n",
    "# convert to a float and set this as the value of the column, we do this since bathrooms text has less missing values than bathrooms\n",
    "\n",
    "non_numeric_baths = ['Half-bath', 'Private half-bath', 'Shared half-bath']\n",
    "\n",
    "df.loc[df[\"bathrooms\"].isna(), \"bathrooms\"] = df.loc[df[\"bathrooms\"].isna(), \"bathrooms_text\"].apply(\n",
    "    lambda x: 0.5 if x in non_numeric_baths else float(x.split()[0])\n",
    ")\n",
    "\n",
    "# For bedrooms, use median which is one \n",
    "df.fillna({\n",
    "    \"bedrooms\": df[\"bedrooms\"].median()\n",
    "}, inplace=True)\n",
    "\n",
    "# For beds, if the value is NaN take the number of people the property accomodates and divide it by 2\n",
    "# Most airbnb listings have a bed being able to accomodate 2 people, so dividing accomodates by 2 will give us a good estimate of the number of beds\n",
    "df.loc[df[\"beds\"].isna(), \"beds\"] = df.loc[df[\"beds\"].isna(), \"accommodates\"].apply(\n",
    "    lambda x: np.ceil(x / 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle rest of numerical columns: price, reviews_score_*, *_nights\n",
    "# For price, first convert to numerical, then set the price based on the average price of the neighborhood the lisiting is in\n",
    "df[\"price\"] = df[\"price\"].replace({r'\\$': '', r',': ''}, regex=True).astype(float)\n",
    "\n",
    "# !!! May want to change this to do mean of bourough instead incase certain neigborhoods have a low amount of samples !!!\n",
    "grouped_means = df.groupby(\"neighbourhood_cleansed\")[\"price\"].transform('mean')\n",
    "df[\"price\"] = df[\"price\"].fillna(grouped_means)\n",
    "\n",
    "# Fill last missing price with mean of the bourough\n",
    "grouped_bourough_means = df.groupby(\"neighbourhood_group_cleansed\")[\"price\"].transform('mean')\n",
    "\n",
    "df[\"price\"] = df[\"price\"].fillna(grouped_bourough_means)\n",
    "\n",
    "# for review_scores columns, Fill NA with 0, \n",
    "# however we may end up not using these columns since we are going to make an column based on the sentiments of the reivews\n",
    "\n",
    "df.fillna({\n",
    "    \"review_scores_rating\": 0.0,\n",
    "    \"review_scores_accuracy\": 0.0,\n",
    "    \"review_scores_cleanliness\": 0.0,\n",
    "    \"review_scores_checkin\": 0.0,\n",
    "    \"review_scores_communication\": 0.0,\n",
    "    \"review_scores_location\": 0.0,\n",
    "    \"review_scores_value\" : 0.0\n",
    "}, inplace=True)\n",
    "\n",
    "# For reviews per month, use number of reviews divided by months since starting to be a host, assume current date is date of last scrape or 9/6/24\n",
    "\n",
    "current_date = datetime(2024, 9, 6)\n",
    "df['host_since'] = pd.to_datetime(df['host_since'])\n",
    "\n",
    "\n",
    "df.loc[df[\"reviews_per_month\"].isna(), \"reviews_per_month\"] = (\n",
    "    df.loc[df['reviews_per_month'].isna(), 'number_of_reviews'] / \n",
    "    np.ceil(((current_date - df.loc[df['reviews_per_month'].isna(), 'host_since']).dt.days) / 30)\n",
    ")\n",
    "\n",
    "# For the max,min, nights columns since there is only one row with missing values we can just remove it\n",
    "df.dropna(subset=[\n",
    "    \"minimum_minimum_nights\",\n",
    "    \"maximum_minimum_nights\",\n",
    "    \"minimum_maximum_nights\",\n",
    "    \"maximum_maximum_nights\",\n",
    "    \"minimum_nights_avg_ntm\",\n",
    "    \"maximum_nights_avg_ntm\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for any remaining NA values\n",
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Datatypes of columns\n",
    "\n",
    "Some of the columns currently have type object, for example price needs to be converted to a numerical object, and the True/False columns need to be converted to Boolean/0,1 columns.\n",
    "\n",
    "Columns to convert:\n",
    "- host_is_superhost\n",
    "- host_has_profile_pic\n",
    "- host_identity_verified\n",
    "- has_availability\n",
    "- instant_bookable\n",
    "- license (Convert to a 3 catergorical variable, either No license, Exempt, or Has license)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: int64\n",
      "last_scraped: object\n",
      "name: object\n",
      "description: object\n",
      "neighborhood_overview: object\n",
      "picture_url: object\n",
      "host_id: int64\n",
      "host_name: object\n",
      "host_since: datetime64[ns]\n",
      "host_location: object\n",
      "host_about: object\n",
      "host_response_time: object\n",
      "host_response_rate: float64\n",
      "host_acceptance_rate: float64\n",
      "host_is_superhost: object\n",
      "host_neighbourhood: object\n",
      "host_listings_count: float64\n",
      "host_total_listings_count: float64\n",
      "host_verifications: object\n",
      "host_has_profile_pic: object\n",
      "host_identity_verified: object\n",
      "neighbourhood_cleansed: object\n",
      "neighbourhood_group_cleansed: object\n",
      "latitude: float64\n",
      "longitude: float64\n",
      "property_type: object\n",
      "room_type: object\n",
      "accommodates: int64\n",
      "bathrooms: float64\n",
      "bathrooms_text: object\n",
      "bedrooms: float64\n",
      "beds: float64\n",
      "amenities: object\n",
      "price: float64\n",
      "minimum_nights: int64\n",
      "maximum_nights: int64\n",
      "minimum_minimum_nights: float64\n",
      "maximum_minimum_nights: float64\n",
      "minimum_maximum_nights: float64\n",
      "maximum_maximum_nights: float64\n",
      "minimum_nights_avg_ntm: float64\n",
      "maximum_nights_avg_ntm: float64\n",
      "has_availability: object\n",
      "availability_30: int64\n",
      "availability_60: int64\n",
      "availability_90: int64\n",
      "availability_365: int64\n",
      "number_of_reviews: int64\n",
      "number_of_reviews_ltm: int64\n",
      "number_of_reviews_l30d: int64\n",
      "review_scores_rating: float64\n",
      "review_scores_accuracy: float64\n",
      "review_scores_cleanliness: float64\n",
      "review_scores_checkin: float64\n",
      "review_scores_communication: float64\n",
      "review_scores_location: float64\n",
      "review_scores_value: float64\n",
      "license: object\n",
      "instant_bookable: object\n",
      "calculated_host_listings_count: int64\n",
      "calculated_host_listings_count_entire_homes: int64\n",
      "calculated_host_listings_count_private_rooms: int64\n",
      "calculated_host_listings_count_shared_rooms: int64\n",
      "reviews_per_month: float64\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    print(f'{column}: {df[column].dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afif\\AppData\\Local\\Temp\\ipykernel_41972\\3547918659.py:10: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[bin_cols] = df[bin_cols].replace({\"t\": 1, \"f\":0})\n"
     ]
    }
   ],
   "source": [
    "# Convert Binary Variables t/f to 1/0\n",
    "bin_cols = [\n",
    " \"host_is_superhost\",\n",
    " \"host_has_profile_pic\",\n",
    " \"host_identity_verified\",\n",
    " \"has_availability\",\n",
    " \"instant_bookable\"\n",
    "]\n",
    "\n",
    "df[bin_cols] = df[bin_cols].replace({\"t\": 1, \"f\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert license \n",
    "df[\"license\"] = df[\"license\"].apply(lambda x: x if x == \"No License\" or x == \"Exempt\" else \"Has License\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Final Dataset\n",
    "# df.to_csv(\"Datasets/AirbnbData/All_Listings_Cleaned.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
